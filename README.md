# FineTuningLlama2
Parameter Efficient Fine Tuning of Llama-2 using LoRA

Fine-tuned the Llama-2 language model for question-answering task using Low-Rank Adaptation (LoRA) to enhance performance with minimal computational resources.

Applied LoRA to fine-tune only a small subset of parameters by introducing trainable low-rank matrices, significantly reducing the number of parameters that need updating during training.
